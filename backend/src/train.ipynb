{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd872265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4776c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fbbebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Anxiety_Score</th>\n",
       "      <th>Depression_Score</th>\n",
       "      <th>Daily_Reflections</th>\n",
       "      <th>Sleep_Hours</th>\n",
       "      <th>Steps_Per_Day</th>\n",
       "      <th>Mood_Description</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "      <th>Mental_Health_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>Other</td>\n",
       "      <td>2.52</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>Onto foreign do environmental anyone every nea...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4166</td>\n",
       "      <td>Happy</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.74</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>Party but others visit admit industry country ...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4949</td>\n",
       "      <td>Tired</td>\n",
       "      <td>0.4678</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.53</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>Religious sure wait do chance decade according...</td>\n",
       "      <td>8.3</td>\n",
       "      <td>7632</td>\n",
       "      <td>Sad</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.04</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>A task effect entire coach join series.</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5548</td>\n",
       "      <td>Sad</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>Other</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Knowledge several camera wait week write quali...</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3698</td>\n",
       "      <td>Happy</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>20</td>\n",
       "      <td>Other</td>\n",
       "      <td>3.34</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>Land floor page trade social away animal cut e...</td>\n",
       "      <td>5.4</td>\n",
       "      <td>8725</td>\n",
       "      <td>Motivated</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>18</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>Almost wide majority technology positive parti...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3692</td>\n",
       "      <td>Anxious</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>23</td>\n",
       "      <td>Other</td>\n",
       "      <td>2.86</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>Property answer method call law dream maybe mo...</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6000</td>\n",
       "      <td>Motivated</td>\n",
       "      <td>0.6461</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>18</td>\n",
       "      <td>Female</td>\n",
       "      <td>2.45</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>Care can now outside real rest that perform.</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5013</td>\n",
       "      <td>Stressed</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>18</td>\n",
       "      <td>Other</td>\n",
       "      <td>3.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Get turn Congress list mouth city decision eas...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5440</td>\n",
       "      <td>Anxious</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Student_ID  Age  Gender   GPA  Stress_Level  Anxiety_Score  \\\n",
       "0             1   23   Other  2.52             5             20   \n",
       "1             2   19    Male  2.74             5              3   \n",
       "2             3   21  Female  3.53             5             11   \n",
       "3             4   18    Male  2.04             4             15   \n",
       "4             5   19   Other  2.87             1              2   \n",
       "..          ...  ...     ...   ...           ...            ...   \n",
       "495         496   20   Other  3.34             4              0   \n",
       "496         497   18  Female  3.22             2              7   \n",
       "497         498   23   Other  2.86             4             17   \n",
       "498         499   18  Female  2.45             4             14   \n",
       "499         500   18   Other  3.52             1              0   \n",
       "\n",
       "     Depression_Score                                  Daily_Reflections  \\\n",
       "0                   6  Onto foreign do environmental anyone every nea...   \n",
       "1                   7  Party but others visit admit industry country ...   \n",
       "2                  24  Religious sure wait do chance decade according...   \n",
       "3                  14            A task effect entire coach join series.   \n",
       "4                   4  Knowledge several camera wait week write quali...   \n",
       "..                ...                                                ...   \n",
       "495                21  Land floor page trade social away animal cut e...   \n",
       "496                 3  Almost wide majority technology positive parti...   \n",
       "497                 1  Property answer method call law dream maybe mo...   \n",
       "498                 0       Care can now outside real rest that perform.   \n",
       "499                 5  Get turn Congress list mouth city decision eas...   \n",
       "\n",
       "     Sleep_Hours  Steps_Per_Day Mood_Description  Sentiment_Score  \\\n",
       "0            6.8           4166            Happy           0.0000   \n",
       "1            5.1           4949            Tired           0.4678   \n",
       "2            8.3           7632              Sad           0.5106   \n",
       "3            8.2           5548              Sad           0.2960   \n",
       "4            5.9           3698            Happy           0.4588   \n",
       "..           ...            ...              ...              ...   \n",
       "495          5.4           8725        Motivated          -0.2732   \n",
       "496          4.5           3692          Anxious           0.7269   \n",
       "497          8.2           6000        Motivated           0.6461   \n",
       "498          6.0           5013         Stressed           0.4939   \n",
       "499          5.6           5440          Anxious           0.4404   \n",
       "\n",
       "     Mental_Health_Status  \n",
       "0                       2  \n",
       "1                       2  \n",
       "2                       2  \n",
       "3                       2  \n",
       "4                       0  \n",
       "..                    ...  \n",
       "495                     2  \n",
       "496                     0  \n",
       "497                     2  \n",
       "498                     1  \n",
       "499                     0  \n",
       "\n",
       "[500 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path('..') / 'data' / 'raw' / 'mental_health_dataset.csv'\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7f71280",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop(columns=[\n",
    "    \"Student_ID\",\n",
    "    \"Daily_Reflections\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdfa3313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Anxiety_Score</th>\n",
       "      <th>Depression_Score</th>\n",
       "      <th>Sleep_Hours</th>\n",
       "      <th>Steps_Per_Day</th>\n",
       "      <th>Mood_Description</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "      <th>Mental_Health_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>Other</td>\n",
       "      <td>2.52</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4166</td>\n",
       "      <td>Happy</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.74</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4949</td>\n",
       "      <td>Tired</td>\n",
       "      <td>0.4678</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.53</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>8.3</td>\n",
       "      <td>7632</td>\n",
       "      <td>Sad</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.04</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5548</td>\n",
       "      <td>Sad</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>Other</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3698</td>\n",
       "      <td>Happy</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>20</td>\n",
       "      <td>Other</td>\n",
       "      <td>3.34</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>5.4</td>\n",
       "      <td>8725</td>\n",
       "      <td>Motivated</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>18</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3692</td>\n",
       "      <td>Anxious</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>23</td>\n",
       "      <td>Other</td>\n",
       "      <td>2.86</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6000</td>\n",
       "      <td>Motivated</td>\n",
       "      <td>0.6461</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>18</td>\n",
       "      <td>Female</td>\n",
       "      <td>2.45</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5013</td>\n",
       "      <td>Stressed</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>18</td>\n",
       "      <td>Other</td>\n",
       "      <td>3.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5440</td>\n",
       "      <td>Anxious</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gender   GPA  Stress_Level  Anxiety_Score  Depression_Score  \\\n",
       "0     23   Other  2.52             5             20                 6   \n",
       "1     19    Male  2.74             5              3                 7   \n",
       "2     21  Female  3.53             5             11                24   \n",
       "3     18    Male  2.04             4             15                14   \n",
       "4     19   Other  2.87             1              2                 4   \n",
       "..   ...     ...   ...           ...            ...               ...   \n",
       "495   20   Other  3.34             4              0                21   \n",
       "496   18  Female  3.22             2              7                 3   \n",
       "497   23   Other  2.86             4             17                 1   \n",
       "498   18  Female  2.45             4             14                 0   \n",
       "499   18   Other  3.52             1              0                 5   \n",
       "\n",
       "     Sleep_Hours  Steps_Per_Day Mood_Description  Sentiment_Score  \\\n",
       "0            6.8           4166            Happy           0.0000   \n",
       "1            5.1           4949            Tired           0.4678   \n",
       "2            8.3           7632              Sad           0.5106   \n",
       "3            8.2           5548              Sad           0.2960   \n",
       "4            5.9           3698            Happy           0.4588   \n",
       "..           ...            ...              ...              ...   \n",
       "495          5.4           8725        Motivated          -0.2732   \n",
       "496          4.5           3692          Anxious           0.7269   \n",
       "497          8.2           6000        Motivated           0.6461   \n",
       "498          6.0           5013         Stressed           0.4939   \n",
       "499          5.6           5440          Anxious           0.4404   \n",
       "\n",
       "     Mental_Health_Status  \n",
       "0                       2  \n",
       "1                       2  \n",
       "2                       2  \n",
       "3                       2  \n",
       "4                       0  \n",
       "..                    ...  \n",
       "495                     2  \n",
       "496                     0  \n",
       "497                     2  \n",
       "498                     1  \n",
       "499                     0  \n",
       "\n",
       "[500 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3e1ba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (500, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Mental_Health_Status\n",
       "2    341\n",
       "1    137\n",
       "0     22\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Features/label\n",
    "X = df.drop(columns=[\"Mental_Health_Status\"])\n",
    "y = df[\"Mental_Health_Status\"]\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "display(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7fd452d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (500, 11)\n",
      "\n",
      "Columns: ['Age', 'Gender', 'GPA', 'Stress_Level', 'Anxiety_Score', 'Depression_Score', 'Sleep_Hours', 'Steps_Per_Day', 'Mood_Description', 'Sentiment_Score', 'Mental_Health_Status']\n",
      "\n",
      "Missing values per column (top 20):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age                     0\n",
       "Gender                  0\n",
       "GPA                     0\n",
       "Stress_Level            0\n",
       "Anxiety_Score           0\n",
       "Depression_Score        0\n",
       "Sleep_Hours             0\n",
       "Steps_Per_Day           0\n",
       "Mood_Description        0\n",
       "Sentiment_Score         0\n",
       "Mental_Health_Status    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Mental_Health_Status\n",
       "2    341\n",
       "1    137\n",
       "0     22\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Mental_Health_Status\n",
       "2    68.2\n",
       "1    27.4\n",
       "0     4.4\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick data sanity checks\n",
    "print('Shape:', df.shape)\n",
    "print('\\nColumns:', list(df.columns))\n",
    "\n",
    "print('\\nMissing values per column (top 20):')\n",
    "display(df.isna().sum().sort_values(ascending=False).head(20))\n",
    "\n",
    "print('\\nLabel distribution:')\n",
    "display(df['Mental_Health_Status'].value_counts(dropna=False))\n",
    "display((df['Mental_Health_Status'].value_counts(normalize=True, dropna=False) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8ec5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3b41790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define feature types\n",
    "categorical_cols = [\"Gender\", \"Mood_Description\"]\n",
    "numeric_cols = [c for c in X.columns if c not in categorical_cols]\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    " )\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    " )\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbd78ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (400, 10)  Test size: (100, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    " )\n",
    "\n",
    "print('Train size:', X_train.shape, ' Test size:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cad2a636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 10)\n",
      "(100, 10)\n",
      "(400,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1900e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 34 candidates, totalling 170 fits\n",
      "Best CV balanced_accuracy: 0.8303030303030303\n",
      "Best params: {'model': RandomForestClassifier(class_weight='balanced_subsample', random_state=42), 'model__max_depth': 8, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 300}\n",
      "\n",
      "Holdout Accuracy: 0.96\n",
      "Holdout Balanced Accuracy: 0.7876543209876544\n",
      "Holdout Macro F1: 0.8309002433090025\n",
      "Holdout Weighted F1: 0.9543222106360792\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57         5\n",
      "           1       0.90      0.96      0.93        27\n",
      "           2       0.99      1.00      0.99        68\n",
      "\n",
      "    accuracy                           0.96       100\n",
      "   macro avg       0.96      0.79      0.83       100\n",
      "weighted avg       0.96      0.96      0.95       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    " )\n",
    "\n",
    "# Pipeline: preprocess -> model\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\", LogisticRegression(max_iter=5000, class_weight=\"balanced\")),\n",
    "    ]\n",
    " )\n",
    "\n",
    "# Try a couple strong baselines and tune them\n",
    "param_grid = [\n",
    "    {\n",
    "        \"model\": [LogisticRegression(max_iter=5000, class_weight=\"balanced\", solver=\"saga\")],\n",
    "        \"model__C\": [0.1, 0.3, 1.0, 3.0, 10.0],\n",
    "        \"model__penalty\": [\"l1\", \"l2\"],\n",
    "    },\n",
    "    {\n",
    "        \"model\": [\n",
    "            RandomForestClassifier(\n",
    "                random_state=42,\n",
    "                class_weight=\"balanced_subsample\",\n",
    "            )\n",
    "        ],\n",
    "        \"model__n_estimators\": [300, 600],\n",
    "        \"model__max_depth\": [None, 8, 16],\n",
    "        \"model__min_samples_split\": [2, 5],\n",
    "        \"model__min_samples_leaf\": [1, 2],\n",
    "    },\n",
    " ]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Use balanced_accuracy so the model doesn't win by ignoring the rare class\n",
    "search = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    " )\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "best_model = search.best_estimator_\n",
    "print('Best CV balanced_accuracy:', search.best_score_)\n",
    "print('Best params:', search.best_params_)\n",
    "\n",
    "# Holdout evaluation\n",
    "y_pred = best_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "bacc = balanced_accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "weighted_f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "print('\\nHoldout Accuracy:', acc)\n",
    "print('Holdout Balanced Accuracy:', bacc)\n",
    "print('Holdout Macro F1:', macro_f1)\n",
    "print('Holdout Weighted F1:', weighted_f1)\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3536ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\models\\\\mental_health_model.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path('..') / 'models' / 'mental_health_model.pkl'\n",
    "joblib.dump(best_model, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa888f98",
   "metadata": {},
   "source": [
    "# By using another model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbe8dfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "ExtraTrees best CV balanced_accuracy: 0.81989898989899\n",
      "ExtraTrees best params: {'model__max_depth': None, 'model__max_features': 'sqrt', 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 800}\n",
      "\n",
      "ExtraTrees Holdout Accuracy: 0.9\n",
      "ExtraTrees Holdout Balanced Accuracy: 0.6815904139433551\n",
      "ExtraTrees Holdout Macro F1: 0.6825784868759649\n",
      "ExtraTrees Holdout Weighted F1: 0.8956497683993825\n",
      "\n",
      "ExtraTrees Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.20      0.25         5\n",
      "           1       0.77      0.89      0.83        27\n",
      "           2       0.98      0.96      0.97        68\n",
      "\n",
      "    accuracy                           0.90       100\n",
      "   macro avg       0.70      0.68      0.68       100\n",
      "weighted avg       0.90      0.90      0.90       100\n",
      "\n",
      "\n",
      "Saved ExtraTrees model to: ..\\models\\mental_health_model_extratrees.pkl\n"
     ]
    }
   ],
   "source": [
    "# Train an alternative model (ExtraTrees) using the SAME preprocessing and split above\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    " )\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# Safety check: make sure the earlier cells were run\n",
    "required_vars = [\"preprocess\", \"X_train\", \"X_test\", \"y_train\", \"y_test\"]\n",
    "missing = [v for v in required_vars if v not in globals()]\n",
    "if missing:\n",
    "    raise NameError(f\"Run the cells above first. Missing: {missing}\")\n",
    "\n",
    "alt_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\n",
    "            \"model\",\n",
    "            ExtraTreesClassifier(\n",
    "                random_state=42,\n",
    "                class_weight=\"balanced\",\n",
    "                n_jobs=-1,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    " )\n",
    "\n",
    "alt_param_grid = {\n",
    "    \"model__n_estimators\": [500, 800],\n",
    "    \"model__max_depth\": [None, 12, 20],\n",
    "    \"model__min_samples_split\": [2, 5],\n",
    "    \"model__min_samples_leaf\": [1, 2],\n",
    "    \"model__max_features\": [\"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "alt_search = GridSearchCV(\n",
    "    estimator=alt_pipe,\n",
    "    param_grid=alt_param_grid,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "alt_search.fit(X_train, y_train)\n",
    "alt_best_model = alt_search.best_estimator_\n",
    "\n",
    "print(\"ExtraTrees best CV balanced_accuracy:\", alt_search.best_score_)\n",
    "print(\"ExtraTrees best params:\", alt_search.best_params_)\n",
    "\n",
    "# Holdout evaluation (same metrics as above)\n",
    "alt_pred = alt_best_model.predict(X_test)\n",
    "alt_acc = accuracy_score(y_test, alt_pred)\n",
    "alt_bacc = balanced_accuracy_score(y_test, alt_pred)\n",
    "alt_macro_f1 = f1_score(y_test, alt_pred, average=\"macro\")\n",
    "alt_weighted_f1 = f1_score(y_test, alt_pred, average=\"weighted\")\n",
    "\n",
    "print(\"\\nExtraTrees Holdout Accuracy:\", alt_acc)\n",
    "print(\"ExtraTrees Holdout Balanced Accuracy:\", alt_bacc)\n",
    "print(\"ExtraTrees Holdout Macro F1:\", alt_macro_f1)\n",
    "print(\"ExtraTrees Holdout Weighted F1:\", alt_weighted_f1)\n",
    "print(\"\\nExtraTrees Classification Report:\\n\", classification_report(y_test, alt_pred))\n",
    "\n",
    "# Save this alternative model too\n",
    "ALT_MODEL_PATH = Path('..') / 'models' / 'mental_health_model_extratrees.pkl'\n",
    "joblib.dump(alt_best_model, ALT_MODEL_PATH)\n",
    "print(\"\\nSaved ExtraTrees model to:\", ALT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c976cd",
   "metadata": {},
   "source": [
    "# another model\n",
    "\n",
    "#### his new section trains LinearSVC (SVM) + CalibratedClassifierCV (good for sparse one‑hot features), evaluates with the same metrics, and saves to mental_health_model_linearsvc.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7311630c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "LinearSVC best CV balanced_accuracy: 0.5150392817059484\n",
      "LinearSVC best params: {'model__estimator__C': 0.1}\n",
      "\n",
      "LinearSVC Holdout Accuracy: 0.81\n",
      "LinearSVC Holdout Balanced Accuracy: 0.5161583151779231\n",
      "LinearSVC Holdout Macro F1: 0.5100762527233115\n",
      "LinearSVC Holdout Weighted F1: 0.7833006535947713\n",
      "\n",
      "LinearSVC Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.67      0.59      0.63        27\n",
      "           2       0.86      0.96      0.90        68\n",
      "\n",
      "    accuracy                           0.81       100\n",
      "   macro avg       0.51      0.52      0.51       100\n",
      "weighted avg       0.76      0.81      0.78       100\n",
      "\n",
      "\n",
      "Saved LinearSVC model to: ..\\models\\mental_health_model_linearsvc.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\ai_course\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\anaconda3\\envs\\ai_course\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\anaconda3\\envs\\ai_course\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Another model (Linear SVM) that often performs well on sparse one-hot features\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    " )\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# Safety check: make sure the earlier cells were run\n",
    "required_vars = [\"preprocess\", \"cv\", \"X_train\", \"X_test\", \"y_train\", \"y_test\"]\n",
    "missing = [v for v in required_vars if v not in globals()]\n",
    "if missing:\n",
    "    raise NameError(f\"Run the cells above first. Missing: {missing}\")\n",
    "\n",
    "# LinearSVC is strong for high-dimensional sparse data; calibration adds predict_proba-like behavior\n",
    "svm_base = LinearSVC(class_weight=\"balanced\", random_state=42)\n",
    "svm = CalibratedClassifierCV(estimator=svm_base, method=\"sigmoid\", cv=3)\n",
    "\n",
    "svm_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\", svm),\n",
    "    ]\n",
    " )\n",
    "\n",
    "svm_param_grid = {\n",
    "    # CalibratedClassifierCV exposes the base estimator via estimator__...\n",
    "    \"model__estimator__C\": [0.1, 0.3, 1.0, 3.0, 10.0],\n",
    "}\n",
    "\n",
    "svm_search = GridSearchCV(\n",
    "    estimator=svm_pipe,\n",
    "    param_grid=svm_param_grid,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    " )\n",
    "\n",
    "svm_search.fit(X_train, y_train)\n",
    "svm_best_model = svm_search.best_estimator_\n",
    "\n",
    "print(\"LinearSVC best CV balanced_accuracy:\", svm_search.best_score_)\n",
    "print(\"LinearSVC best params:\", svm_search.best_params_)\n",
    "\n",
    "svm_pred = svm_best_model.predict(X_test)\n",
    "svm_acc = accuracy_score(y_test, svm_pred)\n",
    "svm_bacc = balanced_accuracy_score(y_test, svm_pred)\n",
    "svm_macro_f1 = f1_score(y_test, svm_pred, average=\"macro\")\n",
    "svm_weighted_f1 = f1_score(y_test, svm_pred, average=\"weighted\")\n",
    "\n",
    "print(\"\\nLinearSVC Holdout Accuracy:\", svm_acc)\n",
    "print(\"LinearSVC Holdout Balanced Accuracy:\", svm_bacc)\n",
    "print(\"LinearSVC Holdout Macro F1:\", svm_macro_f1)\n",
    "print(\"LinearSVC Holdout Weighted F1:\", svm_weighted_f1)\n",
    "print(\"\\nLinearSVC Classification Report:\\n\", classification_report(y_test, svm_pred))\n",
    "\n",
    "SVM_MODEL_PATH = Path('..') / 'models' / 'mental_health_model_linearsvc.pkl'\n",
    "joblib.dump(svm_best_model, SVM_MODEL_PATH)\n",
    "print(\"\\nSaved LinearSVC model to:\", SVM_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032f577f",
   "metadata": {},
   "source": [
    "###### Note: this SVM model did not improve results on the current split (its balanced accuracy was lower than the ExtraTrees and your earlier grid search), but it’s now available as an additional model option without touching the earlier pipeline/code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee177d55",
   "metadata": {},
   "source": [
    "# another model to see better accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff5a3f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "== DecisionTree ==\n",
      "Best CV balanced_accuracy: 0.9698989898989898\n",
      "Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "Holdout Accuracy: 1.0\n",
      "Holdout Balanced Accuracy: 1.0\n",
      "Holdout Macro F1: 1.0\n",
      "Holdout Weighted F1: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00        27\n",
      "           2       1.00      1.00      1.00        68\n",
      "\n",
      "    accuracy                           1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n",
      "Saved model to: ..\\models\\mental_health_model_decisiontree.pkl\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "\n",
      "== KNN ==\n",
      "Best CV balanced_accuracy: 0.6338496071829406\n",
      "Best params: {'model__algorithm': 'brute', 'model__metric': 'minkowski', 'model__n_neighbors': 3, 'model__p': 2, 'model__weights': 'distance'}\n",
      "Holdout Accuracy: 0.78\n",
      "Holdout Balanced Accuracy: 0.5461147421931735\n",
      "Holdout Macro F1: 0.5116279069767442\n",
      "Holdout Weighted F1: 0.7703875968992248\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.56      0.81      0.67        27\n",
      "           2       0.92      0.82      0.87        68\n",
      "\n",
      "    accuracy                           0.78       100\n",
      "   macro avg       0.49      0.55      0.51       100\n",
      "weighted avg       0.78      0.78      0.77       100\n",
      "\n",
      "Saved model to: ..\\models\\mental_health_model_knn.pkl\n",
      "\n",
      "Summary (higher balanced_accuracy is better for imbalanced classes):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\ai_course\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\anaconda3\\envs\\ai_course\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\anaconda3\\envs\\ai_course\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cv_balanced_accuracy</th>\n",
       "      <th>holdout_accuracy</th>\n",
       "      <th>holdout_balanced_accuracy</th>\n",
       "      <th>holdout_macro_f1</th>\n",
       "      <th>holdout_weighted_f1</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.969899</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>..\\models\\mental_health_model_decisiontree.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.633850</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.546115</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.770388</td>\n",
       "      <td>..\\models\\mental_health_model_knn.pkl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  cv_balanced_accuracy  holdout_accuracy  \\\n",
       "0  DecisionTree              0.969899              1.00   \n",
       "1           KNN              0.633850              0.78   \n",
       "\n",
       "   holdout_balanced_accuracy  holdout_macro_f1  holdout_weighted_f1  \\\n",
       "0                   1.000000          1.000000             1.000000   \n",
       "1                   0.546115          0.511628             0.770388   \n",
       "\n",
       "                                             path  \n",
       "0  ..\\models\\mental_health_model_decisiontree.pkl  \n",
       "1           ..\\models\\mental_health_model_knn.pkl  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try more algorithms that can work well for this multi-class target\n",
    "# (Uses the SAME preprocess, cv, and train/test split defined above)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    " )\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "required_vars = [\"preprocess\", \"cv\", \"X_train\", \"X_test\", \"y_train\", \"y_test\"]\n",
    "missing = [v for v in required_vars if v not in globals()]\n",
    "if missing:\n",
    "    raise NameError(f\"Run the cells above first. Missing: {missing}\")\n",
    "\n",
    "def evaluate_and_save(model_name: str, estimator, param_grid: dict, out_name: str):\n",
    "    pipe_local = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocess\", preprocess),\n",
    "            (\"model\", estimator),\n",
    "        ]\n",
    "    )\n",
    "    search_local = GridSearchCV(\n",
    "        estimator=pipe_local,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"balanced_accuracy\",\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "    )\n",
    "    search_local.fit(X_train, y_train)\n",
    "    best_local = search_local.best_estimator_\n",
    "\n",
    "    pred = best_local.predict(X_test)\n",
    "    acc_ = accuracy_score(y_test, pred)\n",
    "    bacc_ = balanced_accuracy_score(y_test, pred)\n",
    "    macro_f1_ = f1_score(y_test, pred, average=\"macro\")\n",
    "    weighted_f1_ = f1_score(y_test, pred, average=\"weighted\")\n",
    "\n",
    "    print(\"\\n==\", model_name, \"==\")\n",
    "    print(\"Best CV balanced_accuracy:\", search_local.best_score_)\n",
    "    print(\"Best params:\", search_local.best_params_)\n",
    "    print(\"Holdout Accuracy:\", acc_)\n",
    "    print(\"Holdout Balanced Accuracy:\", bacc_)\n",
    "    print(\"Holdout Macro F1:\", macro_f1_)\n",
    "    print(\"Holdout Weighted F1:\", weighted_f1_)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, pred))\n",
    "\n",
    "    out_path = Path('..') / 'models' / out_name\n",
    "    joblib.dump(best_local, out_path)\n",
    "    print(\"Saved model to:\", out_path)\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"cv_balanced_accuracy\": float(search_local.best_score_),\n",
    "        \"holdout_accuracy\": float(acc_),\n",
    "        \"holdout_balanced_accuracy\": float(bacc_),\n",
    "        \"holdout_macro_f1\": float(macro_f1_),\n",
    "        \"holdout_weighted_f1\": float(weighted_f1_),\n",
    "        \"path\": str(out_path),\n",
    "    }\n",
    "\n",
    "results = []\n",
    "\n",
    "# 1) Decision Tree (fast baseline; can capture nonlinear interactions)\n",
    "dt = DecisionTreeClassifier(random_state=42, class_weight=\"balanced\")\n",
    "dt_grid = {\n",
    "    \"model__max_depth\": [None, 6, 10, 16],\n",
    "    \"model__min_samples_split\": [2, 5, 10],\n",
    "    \"model__min_samples_leaf\": [1, 2, 4],\n",
    "}\n",
    "results.append(evaluate_and_save(\"DecisionTree\", dt, dt_grid, \"mental_health_model_decisiontree.pkl\"))\n",
    "\n",
    "# 2) KNN (works on sparse output if we force brute search)\n",
    "knn = KNeighborsClassifier()\n",
    "knn_grid = {\n",
    "    \"model__n_neighbors\": [3, 5, 7, 11, 15],\n",
    "    \"model__weights\": [\"uniform\", \"distance\"],\n",
    "    \"model__metric\": [\"minkowski\"],\n",
    "    \"model__p\": [1, 2],\n",
    "    \"model__algorithm\": [\"brute\"],\n",
    "}\n",
    "results.append(evaluate_and_save(\"KNN\", knn, knn_grid, \"mental_health_model_knn.pkl\"))\n",
    "\n",
    "# Summary table (sorted by balanced accuracy)\n",
    "results_df = pd.DataFrame(results).sort_values(\"holdout_balanced_accuracy\", ascending=False)\n",
    "print(\"\\nSummary (higher balanced_accuracy is better for imbalanced classes):\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a76ca1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: (500, 11)\n",
      "Train/Test sizes: (400, 10) (100, 10)\n",
      "\n",
      "Duplicate feature rows in full dataset: 0\n",
      "Duplicate feature rows overlapping Train↔Test: 0\n",
      "No exact Train↔Test duplicate feature rows detected.\n",
      "\n",
      "Max #target-labels per 'Gender' category: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "Female    3\n",
       "Male      3\n",
       "Other     3\n",
       "Name: Mental_Health_Status, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Max #target-labels per 'Mood_Description' category: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Mood_Description\n",
       "Anxious      3\n",
       "Happy        3\n",
       "Motivated    3\n",
       "Relaxed      3\n",
       "Sad          3\n",
       "Stressed     3\n",
       "Tired        3\n",
       "Name: Mental_Health_Status, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Saved DecisionTree] classification report (zero_division=0):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00        27\n",
      "           2       1.00      1.00      1.00        68\n",
      "\n",
      "    accuracy                           1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2\n",
       "0  5   0   0\n",
       "1  0  27   0\n",
       "2  0   0  68"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree depth: 5  | leaves: 10\n",
      "\n",
      "[Saved KNN] classification report (zero_division=0):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.56      0.81      0.67        27\n",
      "           2       0.92      0.82      0.87        68\n",
      "\n",
      "    accuracy                           0.78       100\n",
      "   macro avg       0.49      0.55      0.51       100\n",
      "weighted avg       0.78      0.78      0.77       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sanity-check: why did DecisionTree get 1.0 accuracy?\n",
    "# This does NOT change any earlier code; it just checks for leakage/duplicates and re-evaluates saved models.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "required_vars = [\"df\", \"X\", \"y\", \"X_train\", \"X_test\", \"y_train\", \"y_test\"]\n",
    "missing = [v for v in required_vars if v not in globals()]\n",
    "if missing:\n",
    "    raise NameError(f\"Run the cells above first. Missing: {missing}\")\n",
    "\n",
    "print(\"Rows:\", df.shape)\n",
    "print(\"Train/Test sizes:\", X_train.shape, X_test.shape)\n",
    "\n",
    "# 1) Check exact duplicate rows (features) in the whole dataset\n",
    "dup_all = df.duplicated(subset=X.columns.tolist(), keep=False).sum()\n",
    "print(\"\\nDuplicate feature rows in full dataset:\", int(dup_all))\n",
    "\n",
    "# 2) Check if any identical feature rows appear in BOTH train and test\n",
    "train_hash = pd.util.hash_pandas_object(X_train, index=False)\n",
    "test_hash = pd.util.hash_pandas_object(X_test, index=False)\n",
    "overlap = np.intersect1d(train_hash.values, test_hash.values)\n",
    "print(\"Duplicate feature rows overlapping Train↔Test:\", int(len(overlap)))\n",
    "\n",
    "# 3) If overlapping duplicates exist, check if their labels are always the same (leakage risk)\n",
    "if len(overlap) > 0:\n",
    "    train_idx = train_hash[train_hash.isin(overlap)].index\n",
    "    test_idx = test_hash[test_hash.isin(overlap)].index\n",
    "    train_pairs = pd.DataFrame({\"row_hash\": train_hash.loc[train_idx].values, \"y\": y_train.loc[train_idx].values})\n",
    "    test_pairs = pd.DataFrame({\"row_hash\": test_hash.loc[test_idx].values, \"y\": y_test.loc[test_idx].values})\n",
    "    merged = train_pairs.merge(test_pairs, on=\"row_hash\", suffixes=(\"_train\", \"_test\"))\n",
    "    disagree = (merged[\"y_train\"] != merged[\"y_test\"]).sum()\n",
    "    print(\"Overlapping duplicates with different labels:\", int(disagree))\n",
    "else:\n",
    "    print(\"No exact Train↔Test duplicate feature rows detected.\")\n",
    "\n",
    "# 4) Quick check: does any categorical value map 1-to-1 to the target? (strong signal / possible leakage)\n",
    "for col in [c for c in X.columns if df[c].dtype == \"object\"]:\n",
    "    nunique_max = df.groupby(col)[\"Mental_Health_Status\"].nunique().max()\n",
    "    print(f\"\\nMax #target-labels per '{col}' category:\", int(nunique_max))\n",
    "    display(df.groupby(col)[\"Mental_Health_Status\"].nunique().sort_values(ascending=False).head(10))\n",
    "\n",
    "# 5) Re-evaluate the SAVED decision tree model on the same holdout (no warnings)\n",
    "MODELS_DIR = Path('..') / 'models'\n",
    "dt_path = MODELS_DIR / 'mental_health_model_decisiontree.pkl'\n",
    "knn_path = MODELS_DIR / 'mental_health_model_knn.pkl'\n",
    "\n",
    "if dt_path.exists():\n",
    "    dt_model = joblib.load(dt_path)\n",
    "    dt_pred = dt_model.predict(X_test)\n",
    "    print(\"\\n[Saved DecisionTree] classification report (zero_division=0):\")\n",
    "    print(classification_report(y_test, dt_pred, zero_division=0))\n",
    "    print(\"Confusion matrix:\")\n",
    "    display(pd.DataFrame(confusion_matrix(y_test, dt_pred), index=sorted(y.unique()), columns=sorted(y.unique())))\n",
    "    if hasattr(dt_model, \"named_steps\") and \"model\" in dt_model.named_steps:\n",
    "        model_obj = dt_model.named_steps[\"model\"]\n",
    "        if hasattr(model_obj, \"get_depth\"):\n",
    "            print(\"Tree depth:\", model_obj.get_depth(), \" | leaves:\", model_obj.get_n_leaves())\n",
    "else:\n",
    "    print(\"\\nDecisionTree model file not found:\", dt_path)\n",
    "\n",
    "if knn_path.exists():\n",
    "    knn_model = joblib.load(knn_path)\n",
    "    knn_pred = knn_model.predict(X_test)\n",
    "    print(\"\\n[Saved KNN] classification report (zero_division=0):\")\n",
    "    print(classification_report(y_test, knn_pred, zero_division=0))\n",
    "else:\n",
    "    print(\"\\nKNN model file not found:\", knn_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf05464",
   "metadata": {},
   "source": [
    "# esamble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89017d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded decision_tree from mental_health_model_decisiontree.pkl\n",
      "✓ Loaded random_forest from mental_health_model.pkl\n",
      "✓ Loaded extra_trees from mental_health_model_extratrees.pkl\n",
      "✓ Loaded knn from mental_health_model_knn.pkl\n",
      "✓ Loaded linear_svc from mental_health_model_linearsvc.pkl\n",
      "\n",
      "Creating ensemble with 5 models...\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Method: Voting Classifier combining all 5 trained models\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    ")\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# Safety check\n",
    "required_vars = [\"X_train\", \"X_test\", \"y_train\", \"y_test\"]\n",
    "missing = [v for v in required_vars if v not in globals()]\n",
    "if missing:\n",
    "    raise NameError(f\"Run the cells above first. Missing: {missing}\")\n",
    "\n",
    "MODELS_DIR = Path('..') / 'models'\n",
    "\n",
    "# Load all 5 trained models\n",
    "model_paths = {\n",
    "    'decision_tree': MODELS_DIR / 'mental_health_model_decisiontree.pkl',\n",
    "    'random_forest': MODELS_DIR / 'mental_health_model.pkl',\n",
    "    'extra_trees': MODELS_DIR / 'mental_health_model_extratrees.pkl',\n",
    "    'knn': MODELS_DIR / 'mental_health_model_knn.pkl',\n",
    "    'linear_svc': MODELS_DIR / 'mental_health_model_linearsvc.pkl',\n",
    "}\n",
    "\n",
    "# Load models that exist\n",
    "loaded_models = []\n",
    "for name, path in model_paths.items():\n",
    "    if path.exists():\n",
    "        model = joblib.load(path)\n",
    "        loaded_models.append((name, model))\n",
    "        print(f\"✓ Loaded {name} from {path.name}\")\n",
    "    else:\n",
    "        print(f\"✗ Model not found: {path.name}\")\n",
    "\n",
    "if len(loaded_models) < 2:\n",
    "    raise ValueError(\"Need at least 2 models for ensemble. Train more models first.\")\n",
    "\n",
    "print(f\"\\nCreating ensemble with {len(loaded_models)} models...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89017d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting hard voting ensemble...\n",
      "\n",
      "=== Hard Voting Ensemble Results ===\n",
      "Holdout Accuracy: 0.9500\n",
      "Holdout Balanced Accuracy: 0.7210\n",
      "Holdout Macro F1: 0.7461\n",
      "Holdout Weighted F1: 0.9380\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33         5\n",
      "           1       0.87      0.96      0.91        27\n",
      "           2       0.99      1.00      0.99        68\n",
      "\n",
      "    accuracy                           0.95       100\n",
      "   macro avg       0.95      0.72      0.75       100\n",
      "weighted avg       0.95      0.95      0.94       100\n",
      "\n",
      "\n",
      "✓ Saved hard voting ensemble to: ..\\models\\mental_health_model_ensemble_hard.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create Voting Classifier (hard voting - majority vote)\n",
    "ensemble_hard = VotingClassifier(\n",
    "    estimators=loaded_models,\n",
    "    voting='hard',  # Majority vote\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the ensemble (this is fast since models are already trained)\n",
    "print(\"Fitting hard voting ensemble...\")\n",
    "ensemble_hard.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_hard = ensemble_hard.predict(X_test)\n",
    "acc_hard = accuracy_score(y_test, y_pred_hard)\n",
    "bacc_hard = balanced_accuracy_score(y_test, y_pred_hard)\n",
    "macro_f1_hard = f1_score(y_test, y_pred_hard, average=\"macro\")\n",
    "weighted_f1_hard = f1_score(y_test, y_pred_hard, average=\"weighted\")\n",
    "\n",
    "print(\"\\n=== Hard Voting Ensemble Results ===\")\n",
    "print(f\"Holdout Accuracy: {acc_hard:.4f}\")\n",
    "print(f\"Holdout Balanced Accuracy: {bacc_hard:.4f}\")\n",
    "print(f\"Holdout Macro F1: {macro_f1_hard:.4f}\")\n",
    "print(f\"Holdout Weighted F1: {weighted_f1_hard:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_hard))\n",
    "\n",
    "# Save the hard voting ensemble\n",
    "ENSEMBLE_HARD_PATH = MODELS_DIR / 'mental_health_model_ensemble_hard.pkl'\n",
    "joblib.dump(ensemble_hard, ENSEMBLE_HARD_PATH)\n",
    "print(f\"\\n✓ Saved hard voting ensemble to: {ENSEMBLE_HARD_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89017d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting soft voting ensemble...\n",
      "\n",
      "=== Soft Voting Ensemble Results ===\n",
      "Holdout Accuracy: 0.9700\n",
      "Holdout Balanced Accuracy: 0.8543\n",
      "Holdout Macro F1: 0.8961\n",
      "Holdout Weighted F1: 0.9678\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75         5\n",
      "           1       0.93      0.96      0.95        27\n",
      "           2       0.99      1.00      0.99        68\n",
      "\n",
      "    accuracy                           0.97       100\n",
      "   macro avg       0.97      0.85      0.90       100\n",
      "weighted avg       0.97      0.97      0.97       100\n",
      "\n",
      "\n",
      "✓ Saved soft voting ensemble to: ..\\models\\mental_health_model_ensemble_soft.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create Soft Voting Classifier (weighted by predicted probabilities)\n",
    "# Note: All models must support predict_proba for soft voting\n",
    "try:\n",
    "    ensemble_soft = VotingClassifier(\n",
    "        estimators=loaded_models,\n",
    "        voting='soft',  # Weighted by probabilities\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(\"Fitting soft voting ensemble...\")\n",
    "    ensemble_soft.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred_soft = ensemble_soft.predict(X_test)\n",
    "    acc_soft = accuracy_score(y_test, y_pred_soft)\n",
    "    bacc_soft = balanced_accuracy_score(y_test, y_pred_soft)\n",
    "    macro_f1_soft = f1_score(y_test, y_pred_soft, average=\"macro\")\n",
    "    weighted_f1_soft = f1_score(y_test, y_pred_soft, average=\"weighted\")\n",
    "    \n",
    "    print(\"\\n=== Soft Voting Ensemble Results ===\")\n",
    "    print(f\"Holdout Accuracy: {acc_soft:.4f}\")\n",
    "    print(f\"Holdout Balanced Accuracy: {bacc_soft:.4f}\")\n",
    "    print(f\"Holdout Macro F1: {macro_f1_soft:.4f}\")\n",
    "    print(f\"Holdout Weighted F1: {weighted_f1_soft:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_soft))\n",
    "    \n",
    "    # Save the soft voting ensemble\n",
    "    ENSEMBLE_SOFT_PATH = MODELS_DIR / 'mental_health_model_ensemble_soft.pkl'\n",
    "    joblib.dump(ensemble_soft, ENSEMBLE_SOFT_PATH)\n",
    "    print(f\"\\n✓ Saved soft voting ensemble to: {ENSEMBLE_SOFT_PATH}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Soft voting failed: {e}\")\n",
    "    print(\"Some models may not support predict_proba. Using hard voting only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89017d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON (sorted by Balanced Accuracy)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "      <th>Macro_F1</th>\n",
       "      <th>Weighted_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Individual</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ensemble_soft</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.896052</td>\n",
       "      <td>0.967809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.830900</td>\n",
       "      <td>0.954322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ensemble_hard</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.720988</td>\n",
       "      <td>0.746105</td>\n",
       "      <td>0.938019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>extra_trees</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.681590</td>\n",
       "      <td>0.682578</td>\n",
       "      <td>0.895650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>knn</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.546115</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.770388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linear_svc</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.516158</td>\n",
       "      <td>0.510076</td>\n",
       "      <td>0.783301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model        Type  Accuracy  Balanced_Accuracy  Macro_F1  \\\n",
       "0  decision_tree  Individual      1.00           1.000000  1.000000   \n",
       "6  ensemble_soft    Ensemble      0.97           0.854321  0.896052   \n",
       "1  random_forest  Individual      0.96           0.787654  0.830900   \n",
       "5  ensemble_hard    Ensemble      0.95           0.720988  0.746105   \n",
       "2    extra_trees  Individual      0.90           0.681590  0.682578   \n",
       "3            knn  Individual      0.78           0.546115  0.511628   \n",
       "4     linear_svc  Individual      0.81           0.516158  0.510076   \n",
       "\n",
       "   Weighted_F1  \n",
       "0     1.000000  \n",
       "6     0.967809  \n",
       "1     0.954322  \n",
       "5     0.938019  \n",
       "2     0.895650  \n",
       "3     0.770388  \n",
       "4     0.783301  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 Best Model: decision_tree (Individual)\n",
      "   Balanced Accuracy: 1.0000\n",
      "   Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Compare all models including ensemble\n",
    "import pandas as pd\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "# Individual models\n",
    "for name, model in loaded_models:\n",
    "    pred = model.predict(X_test)\n",
    "    comparison_results.append({\n",
    "        'Model': name,\n",
    "        'Type': 'Individual',\n",
    "        'Accuracy': accuracy_score(y_test, pred),\n",
    "        'Balanced_Accuracy': balanced_accuracy_score(y_test, pred),\n",
    "        'Macro_F1': f1_score(y_test, pred, average='macro'),\n",
    "        'Weighted_F1': f1_score(y_test, pred, average='weighted'),\n",
    "    })\n",
    "\n",
    "# Hard voting ensemble\n",
    "comparison_results.append({\n",
    "    'Model': 'ensemble_hard',\n",
    "    'Type': 'Ensemble',\n",
    "    'Accuracy': acc_hard,\n",
    "    'Balanced_Accuracy': bacc_hard,\n",
    "    'Macro_F1': macro_f1_hard,\n",
    "    'Weighted_F1': weighted_f1_hard,\n",
    "})\n",
    "\n",
    "# Soft voting ensemble (if it worked)\n",
    "if 'acc_soft' in locals():\n",
    "    comparison_results.append({\n",
    "        'Model': 'ensemble_soft',\n",
    "        'Type': 'Ensemble',\n",
    "        'Accuracy': acc_soft,\n",
    "        'Balanced_Accuracy': bacc_soft,\n",
    "        'Macro_F1': macro_f1_soft,\n",
    "        'Weighted_F1': weighted_f1_soft,\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "comparison_df = comparison_df.sort_values('Balanced_Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON (sorted by Balanced Accuracy)\")\n",
    "print(\"=\"*80)\n",
    "display(comparison_df)\n",
    "\n",
    "# Highlight the best model\n",
    "best_model = comparison_df.iloc[0]\n",
    "print(f\"\\n🏆 Best Model: {best_model['Model']} ({best_model['Type']})\")\n",
    "print(f\"   Balanced Accuracy: {best_model['Balanced_Accuracy']:.4f}\")\n",
    "print(f\"   Accuracy: {best_model['Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89017d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VOTING PATTERN ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "All models agree on 67.0% of test cases\n",
      "Models disagree on 33.0% of test cases\n",
      "\n",
      "When all models agree: 100.0% correct\n",
      "When models disagree: 84.8% correct\n",
      "\n",
      "Example cases where models disagree:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision_tree</th>\n",
       "      <th>random_forest</th>\n",
       "      <th>extra_trees</th>\n",
       "      <th>knn</th>\n",
       "      <th>linear_svc</th>\n",
       "      <th>ensemble_hard</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    decision_tree  random_forest  extra_trees  knn  linear_svc  ensemble_hard  \\\n",
       "0               2              2            2    1           2              2   \n",
       "17              1              1            1    1           2              1   \n",
       "19              1              2            2    2           2              2   \n",
       "21              2              2            2    1           1              2   \n",
       "22              2              2            2    1           2              2   \n",
       "\n",
       "    actual  \n",
       "0        2  \n",
       "17       1  \n",
       "19       1  \n",
       "21       2  \n",
       "22       2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze voting patterns - see where models agree/disagree\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VOTING PATTERN ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get predictions from all models\n",
    "all_predictions = {}\n",
    "for name, model in loaded_models:\n",
    "    all_predictions[name] = model.predict(X_test)\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "pred_df = pd.DataFrame(all_predictions)\n",
    "pred_df['ensemble_hard'] = y_pred_hard\n",
    "pred_df['actual'] = y_test.values\n",
    "\n",
    "# Calculate agreement rate\n",
    "def calculate_agreement(row):\n",
    "    model_preds = [row[name] for name, _ in loaded_models]\n",
    "    return len(set(model_preds)) == 1  # True if all agree\n",
    "\n",
    "pred_df['all_agree'] = pred_df.apply(calculate_agreement, axis=1)\n",
    "\n",
    "agreement_rate = pred_df['all_agree'].mean()\n",
    "print(f\"\\nAll models agree on {agreement_rate*100:.1f}% of test cases\")\n",
    "print(f\"Models disagree on {(1-agreement_rate)*100:.1f}% of test cases\")\n",
    "\n",
    "# Check accuracy when models agree vs disagree\n",
    "agree_correct = (pred_df[pred_df['all_agree']]['ensemble_hard'] == pred_df[pred_df['all_agree']]['actual']).mean()\n",
    "disagree_correct = (pred_df[~pred_df['all_agree']]['ensemble_hard'] == pred_df[~pred_df['all_agree']]['actual']).mean()\n",
    "\n",
    "print(f\"\\nWhen all models agree: {agree_correct*100:.1f}% correct\")\n",
    "print(f\"When models disagree: {disagree_correct*100:.1f}% correct\")\n",
    "\n",
    "# Show some examples where models disagree\n",
    "disagreement_cases = pred_df[~pred_df['all_agree']].head(5)\n",
    "if len(disagreement_cases) > 0:\n",
    "    print(f\"\\nExample cases where models disagree:\")\n",
    "    display(disagreement_cases[[name for name, _ in loaded_models] + ['ensemble_hard', 'actual']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89017d50",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The ensemble method combines predictions from all 5 trained models:\n",
    "\n",
    "1. **Hard Voting**: Each model votes for a class, majority wins\n",
    "2. **Soft Voting**: Weighted by predicted probabilities (if supported)\n",
    "\n",
    "### Benefits of Ensemble:\n",
    "- Reduces overfitting by averaging predictions\n",
    "- More robust to individual model weaknesses\n",
    "- Often achieves better generalization\n",
    "\n",
    "### When to Use:\n",
    "- Use ensemble when you want the most reliable prediction\n",
    "- Use individual models when you want to see different perspectives\n",
    "- The comparison table above shows which approach works best for this dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
